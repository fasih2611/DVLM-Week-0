# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qeeH1eVio7if2TtSQR7iX7PPCGnHJCh_
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    def __init__(self, latent_dim=20):
        super(VAE, self).__init__()
        # Encoder
        self.enc_conv1 = nn.Conv2d(1, 32, 4, stride=2, padding=1)  # 28x28 -> 14x14
        self.enc_conv2 = nn.Conv2d(32, 64, 4, stride=2, padding=1) # 14x14 -> 7x7

        self.enc_fc = nn.Linear(64*7*7, 256)
        self.fc_mu = nn.Linear(256, latent_dim)
        self.fc_logvar = nn.Linear(256, latent_dim)

        self.dec_fc = nn.Linear(latent_dim, 256)
        self.dec_fc2 = nn.Linear(256, 64*7*7)
        self.dec_deconv1 = nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1) # 7x7 -> 14x14
        self.dec_deconv2 = nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1)  # 14x14 -> 28x28

    def encode(self, x):
        x = F.relu(self.enc_conv1(x))
        x = F.relu(self.enc_conv2(x))
        x = x.view(x.size(0), -1)
        h = F.relu(self.enc_fc(x))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar



    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5*logvar)
        eps = torch.randn_like(std)
        return mu + eps*std



    def decode(self, z):

        h = F.relu(self.dec_fc(z))
        h = F.relu(self.dec_fc2(h))
        h = h.view(-1, 64, 7, 7)
        h = F.relu(self.dec_deconv1(h))
        x_recon = torch.sigmoid(self.dec_deconv2(h))
        return x_recon



    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

import torch
import torch.nn.functional as F
from torch import optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

def get_loaders(batch_size=128):
    tx = transforms.ToTensor()
    train_set = datasets.FashionMNIST('./data', train=True, download=True, transform=tx)
    test_set = datasets.FashionMNIST('./data', train=False, download=True, transform=tx)
    return DataLoader(train_set, batch_size=batch_size, shuffle=True),DataLoader(test_set, batch_size=batch_size, shuffle=False)

def vae_loss(recon_x, x, mu, logvar):
    # reconstruction should be [batch,1,28,28]
    mse = F.mse_loss(recon_x, x, reduction='sum')
    # from the latent space mu, logvar: [batch,20]
    # the simplified KL diverage loss
    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return mse, kld

def train(model, loader, opt_enc, opt_dec, device, k_steps=1):
    model.train()
    total_mse, total_kld = 0, 0
    for x, _ in loader:
        x = x.to(device)
        # multiple Encoder Updates
        for _ in range(k_steps):
            opt_enc.zero_grad()
            recon, mu, logvar = model(x)
            mse, kld = vae_loss(recon, x, mu, logvar)
            (mse + kld).backward()
            opt_enc.step()
        opt_dec.zero_grad()
        recon, mu, logvar = model(x)
        mse, kld = vae_loss(recon, x, mu, logvar)
        (mse + kld).backward()
        opt_dec.step()
        total_mse += mse.item()
        total_kld += kld.item()

    return total_mse / len(loader.dataset), total_kld / len(loader.dataset)

def visualize_vae(model, loader, device, num_samples=8):
    model.eval()
    with torch.no_grad():
        x, _ = next(iter(loader))
        x = x[:num_samples].to(device)
        recon, _, _ = model(x)
        fig, axes = plt.subplots(2, num_samples, figsize=(12, 4))
        for i in range(num_samples):
            axes[0, i].imshow(x[i].cpu().squeeze(), cmap='gray')
            axes[1, i].imshow(recon[i].cpu().squeeze(), cmap='gray')
            axes[0, i].axis('off')
        plt.show()

def generate_samples(model, device, latent_dim=20, n=10, dist='gaussian'):
    model.eval()
    with torch.no_grad():
        if dist == 'gaussian':
            z = torch.randn(n, latent_dim).to(device)
        else:
            u = torch.rand(n, latent_dim).to(device) - 0.5
            z = -torch.sign(u) * torch.log(1 - 2 * torch.abs(u))

        # z: [n, 20]
        samples = model.decode(z).cpu()

        fig, axes = plt.subplots(1, n, figsize=(15, 2))
        for i in range(n):
            axes[i].imshow(samples[i].squeeze(), cmap='gray')
            axes[i].axis('off')
        plt.title(f"Generated via {dist} prior")
        plt.show()

def run_tasks():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = VAE(latent_dim=20).to(device)
    train_loader, test_loader = get_loaders()

    # Split parameters to train encoder faster
    enc_params = [p for n, p in model.named_parameters() if 'enc' in n or 'fc_mu' in n or 'fc_logvar' in n]
    dec_params = [p for n, p in model.named_parameters() if 'dec' in n]

    opt_enc = optim.AdamW(enc_params, lr=0.01)
    opt_dec = optim.AdamW(dec_params, lr=0.001)

    for epoch in range(1, 31):
        mse, kld = train(model, train_loader, opt_enc, opt_dec, device,k_steps=3) # kstep controls the aggressiveness of training change this to get diff results
        print(f"Epoch {epoch} | MSE: {mse:.4f} | KLD: {kld:.4f}")

    visualize_vae(model, test_loader, device)
    generate_samples(model, device, dist='gaussian')
    generate_samples(model, device, dist='laplacian')

if __name__ == "__main__":
    run_tasks()

